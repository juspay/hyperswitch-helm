services:
  router:
    # -- Router version
    # @section -- Services
    version: v1.114.0
    # -- Router image
    # @section -- Services
    image: docker.juspay.io/juspaydotin/hyperswitch-router:v1.114.0
    # -- Router host
    # @section -- Services
    host: &router_host http://localhost:8080
  consumer:
    # -- Consumer image
    # @section -- Services
    image: docker.juspay.io/juspaydotin/hyperswitch-consumer:v1.114.0
  producer:
    # -- Producer image
    # @section -- Services
    image: docker.juspay.io/juspaydotin/hyperswitch-producer:v1.114.0
  controlCenter:
    # -- Control Center image
    # @section -- Services
    image: docker.juspay.io/juspaydotin/hyperswitch-control-center:v1.37.1
  sdk:
    # -- SDK host
    # @section -- Services
    host: http://localhost:9050
    # -- SDK version
    # @section -- Services
    version: 0.121.2
    # -- SDK subversion
    # @section -- Services
    subversion: v0

# @ignored
global:
  # Number of replicas to be used for the application by default (for server and consumer)
  replicas: 3
  # Wait time allowed for the deployment before the deployment is marked as failed
  progressDeadlineSeconds: 600
  # The strategy that can be used to replace the old pods by new ones
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  # tolerations to be used by the application
  tolerations: []
  # Specify affinity for nodes to which the pods should start on
  # @ignored
  affinity: {}
  # nodeSelector to be used by the application
  nodeSelector: {}
  # -- The time kubernetes will wait after sending the termination signal to the pods
  terminationGracePeriodSeconds: 30
  # -- Annotations that are to be added to the pods
  podAnnotations:
    traffic_sidecar_istio_io_excludeOutboundIPRanges: 10.23.6.12/32
  # -- Annotations that are to be added the the deployments
  annotations:
    deployment.kubernetes.io/revision: "1"
  # -- Labels to be added to the all the deployments and their pods
  labels:
    managedBy: hyperswitch

  # -- service account annotations to be used
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn:
  # -- Environmant variables that are to be used by the hyperswitch application services
  env:
    pod_name:
      name: POD_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.name

  configMap: |
    [server]
    host = 0.0.0.0

  # -- secrets to be used by the hyperswitch application
  secrets:

server:
  # -- Number of replicas to be used for the application
  replicas: 1
  # Wait time allowed for the deployment before the deployment is marked as failed
  progressDeadlineSeconds: 600
  # The strategy that can be used to replace the old pods by new ones
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  # -- The liveness probe configuration for the pods
  # @ignored
  livenessProbe:
    failureThreshold: 3
    httpGet:
      path: /health
      port: 8080
      scheme: HTTP
    initialDelaySeconds: 5
    periodSeconds: 60
    successThreshold: 1
    timeoutSeconds: 1
  # -- The readiness probe configuration for the pods
  # @ignored
  readinessProbe:
    failureThreshold: 3
    httpGet:
      path: /health
      port: 8080
      scheme: HTTP
    initialDelaySeconds: 5
    periodSeconds: 60
    successThreshold: 1
    timeoutSeconds: 1
  # Specify affinity for nodes to which the pods should start on
  # @ignored
  affinity: {}
  # -- The time kubernetes will wait after sending the termination signal to the pods
  terminationGracePeriodSeconds: 30
  # -- Annotations that are to be added to the pods (extends global configuration)
  podAnnotations:
    traffic_sidecar_istio_io_excludeOutboundIPRanges: 10.23.6.12/32
  # -- Annotations that are to be added the the deployments (extends global configuration)
  annotations:
    deployment.kubernetes.io/revision: "1"
  # -- Labels to be added to the deployment's (match labels) and their pods (extends global configuration)
  labels:
    app: hyperswitch-server
  # -- service account annotations to be used
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn: my-role-arn
  # -- Environmant variables that are to be used by the hyperswitch application service this will extend the existing global configuration
  # @ignored
  env:
    binary: router
    host: hyperswitch
  secrets:
    # -- admin API key for admin authentication.
    # @section -- App Server Secrets
    admin_api_key: test_admin
    # -- JWT secret used for user authentication.
    # @section -- App Server Secrets
    jwt_secret: test_admin
    # -- Master Encryption key used to encrypt merchant wise encryption key. Should be 32-byte long.
    # @section -- App Server Secrets
    master_enc_key: 471f22516724347bcca9c20c5fa88d9821c4604e63a6aceffd24605809c9237c
    # -- Recon Admin API key for recon admin authentication.
    # @section -- App Server Secrets
    recon_admin_api_key: test_admin
    # -- KMS key id for encryption and decryption
    # @section -- App Server Secrets
    kms_key_id: kms_key_id
    # -- AWS KMS region
    # @section -- App Server Secrets
    kms_key_region: us-east-1
    # -- The public key for the locker from locker-public-key.pub, these are only test keys, please change it when deploying to production or other environments
    # @section -- App Server Secrets
    # @default -- "-----BEGIN PUBLIC KEY-----...-----END PUBLIC KEY-----"
    kms_jwekey_vault_encryption_key: |
      -----BEGIN PUBLIC KEY-----
      MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsn4glmrihAG7Vppqd3Hm
      RXZiGmuZW0J+NQt72453oSnGc6Sw1Fk/vY0WhQIn6/Ip1Xt6dnMyorI3b9RtfQNP
      DFND3/g7n2I9uMqEr6aYxg0pKw9UW3uBlzR5JzvMVnzEjIRfdtuqSlphdpAVuZPE
      FEN9kE/VasBIeaKmbYFZxmz4AN2IBBvqWCaqIQZOrTRzfGNhVBlX/O+Sv59cy6n6
      QEoYJ/Ww3R7cUlSrueQNlSubkoa8ihBcm9VA7Bdklrps7B17yzMTAgqhZPkLMIQQ
      DBI1vFDlSKrWHNXfm4WyAXJ8MXOl+ThNJdAoDw2wNJmfOrgaPQFiMfPZYgKl/2Gu
      YQIDAQAB
      -----END PUBLIC KEY-----
    # -- The private key for the tenant from tenant-private-key.pem, these are only test keys, please change it when deploying to production or other environments
    # @section -- App Server Secrets
    # @default -- "-----BEGIN RSA PRIVATE KEY-----...-----END RSA PRIVATE KEY-----"
    kms_jwekey_vault_private_key: |
      -----BEGIN PRIVATE KEY-----
      MIIEvAIBADANBgkqhkiG9w0BAQEFAASCBKYwggSiAgEAAoIBAQC0m19nEbqiGX8y
      +TQM6JQq88srVay69393MtYGEoA5tlzwCq8T9GJMvvcc63VLmtfJP9PAN+lwQjyh
      W5JaKQza3KDG6CGq0D+Yr8WjQZdrNH7l9zNAG9W+VQ+kQDhlpSSkuQOViVMuCMYL
      PqYE5a14KFzT6IW/ZjPIB0g5oDuziW6SUBLEvlRmrbQQQdcvjAgoq/l9AuhpWIG/
      dB40Q+FrguhyV1R+SguXQ43XlNasNP+ASCXdqenx/i3JKDJ64E05+yJVViqqeAqo
      1W1xEdJgZzEGbEFXeZOEgf9ic+dKgz9/54MC2si6C62LkH6gl9VbVZTq/ndpB44u
      t3b5dHY9AgMBAAECggEABlQBWj+rreokMLmJnAz6kBMdvDJF/83g1S2rURtZ2Dih
      dgNLa72rqhIkEqSimTHfCLaoHG6SsXPCSX16mcnuOnolI5yjlvQYBMLeTNOYbITl
      qcVPfubaxoH9e9BVb/GC4K144i1Yt3hOoO5vhVfOcoAOv8zaAg3tl4vyks5TksoZ
      WF7ZUFfYiQiF+1+Stdiv+DvJnPUIhHBMol44vuh3SjCbX+t6PqPiAkHpr+8Xu9Qx
      ubKehVOYPs7YY+2s2qqnfgzvx+rHmsyUri+GNH4BoSEYCcY9ErD3sNJajjxchkMv
      9zZsDBgmKFoIT2ZxM9WYu7RqUhUYWz7UNoBcwetXwQKBgQDpYSGjajt1CuPko6HV
      yxMG6hDa4YjChUTgC7Lg5j8a3IGsce/DVurN3d3xApeyr0EHJa3KFwTd4kvF1Ad6
      R9raWgfkaolS4gCK0FywFPDIYzkgg171XOVo1uiiumsgdbbOMgc/3J2mBZPdjhV5
      3QwpDQCTmCjiYv26Or6zg2vp4QKBgQDGHMqrgtQGHNOyeO07ZS+5jua4/CaPdTzc
      gJa30nALo4pc/23H1abDelQD+LMEyAor8DWH1EcGYBa92PWwUupzswICi88uf1ik
      mwKZ+R5+qfGQ4LZEcG9P7Q/Q3j81G7ZJo2hdts+vrQ4ycuw64XIUfMJ0/9Jg0ojY
      kKdXJUNv3QKBgFAzmxXHmis81NhsC1+nbCCCK8ysmQ0QM30zSAPV3HXktYOHnDfr
      FMIuruj2VR+I7rYAEttSUc/WxudzWCaDrwg+zFuI6Sxckoch19iDOcQDpUwxGV8E
      z6nZwRS7L7l1+p6dvrQJovu9CvWmsGayuk0ZNMuEDPjPwBZRvdt/HITBAoGAek3O
      BMIYuMlVG+oxsqhOJUUGRQ9NkuTytMIhycv9ZgIJak46bNMGR8meUnFXu0zvkp6R
      vZAcZOAvSfbF/pvBp7nMNNwxBGiTxdL4cSvtWo751dIUU/4Bihs012JNLTE1gRKD
      XM9+OdshV53BHryNW/6FYguIykNPPjtXQ6J6lnUCgYBbuji9BmsTNCNFdeHdUC9b
      KFMoRFgTomZzgU5sdjNhElizpyQ+B2c8GGaXw/poeevUnW2LPGkIcYiwyvMcEqD0
      3qYrLcDIIEk/uPWvbCH/nNwBL/2zzFoGdreefsPyYacIE0XT8dEqeNNryCunbaEo
      49IwF6OHTk+8yjEF1c5ngQ==
      -----END PRIVATE KEY-----
    # @section -- App Server Secrets
    kms_jwekey_tunnel_private_key: dummy_val
    # @section -- App Server Secrets
    kms_jwekey_rust_locker_encryption_key:  |
      -----BEGIN PUBLIC KEY-----
      MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsn4glmrihAG7Vppqd3Hm
      RXZiGmuZW0J+NQt72453oSnGc6Sw1Fk/vY0WhQIn6/Ip1Xt6dnMyorI3b9RtfQNP
      DFND3/g7n2I9uMqEr6aYxg0pKw9UW3uBlzR5JzvMVnzEjIRfdtuqSlphdpAVuZPE
      FEN9kE/VasBIeaKmbYFZxmz4AN2IBBvqWCaqIQZOrTRzfGNhVBlX/O+Sv59cy6n6
      QEoYJ/Ww3R7cUlSrueQNlSubkoa8ihBcm9VA7Bdklrps7B17yzMTAgqhZPkLMIQQ
      DBI1vFDlSKrWHNXfm4WyAXJ8MXOl+ThNJdAoDw2wNJmfOrgaPQFiMfPZYgKl/2Gu
      YQIDAQAB
      -----END PUBLIC KEY-----
    # @section -- App Server Secrets
    kms_connector_onboarding_paypal_client_id: dummy_val
    # @section -- App Server Secrets
    kms_connector_onboarding_paypal_client_secret: dummy_val
    # @section -- App Server Secrets
    kms_connector_onboarding_paypal_partner_id: dummy_val
    # -- Encryption key for redis temp locker
    # @section -- App Server Secrets
    redis_temp_locker_encryption_key: dummy_val
    # -- Merchant Certificate provided by Apple Pay (https://developer.apple.com/) Certificates, Identifiers & Profiles > Apple Pay Merchant Identity Certificate
    # @section -- App Server Secrets
    apple_pay_merchant_cert: dummy_val
    # -- Private key generated by RSA:2048 algorithm. Refer Hyperswitch Docs (https://docs.hyperswitch.io/hyperswitch-cloud/payment-methods-setup/wallets/apple-pay/ios-application/) to generate the private key
    # @section -- App Server Secrets
    apple_pay_merchant_cert_key: dummy_val
    # -- Payment Processing Certificate provided by Apple Pay (https://developer.apple.com/) Certificates, Identifiers & Profiles > Apple Pay Payment Processing Certificate
    # @section -- App Server Secrets
    apple_pay_ppc: dummy_val
    # -- Private key generated by Elliptic-curve prime256v1 curve. You can use `openssl ecparam -out private.key -name prime256v1 -genkey` to generate the private key
    # @section -- App Server Secrets
    apple_pay_ppc_key: dummy_val
    # -- Merchant Certificate provided by Apple Pay (https://developer.apple.com/) Certificates, Identifiers & Profiles > Apple Pay Merchant Identity Certificate
    # @section -- App Server Secrets
    apple_pay_merchant_conf_merchant_cert: dummy_val
    # -- Private key generate by RSA:2048 algorithm. Refer Hyperswitch Docs (https://docs.hyperswitch.io/hyperswitch-cloud/payment-methods-setup/wallets/apple-pay/ios-application/) to generate the private key
    # @section -- App Server Secrets
    apple_pay_merchant_conf_merchant_cert_key: dummy_val
    # -- Refer to config.example.toml to learn how you can generate this value
    # @section -- App Server Secrets
    apple_pay_merchant_conf_merchant_id: dummy_val
    # -- Api key for making request to foreign exchange Api, Follow https://github.com/juspay/hyperswitch/tree/main/crates/analytics#setting-up-forex-apis to get the forex api key
    # @section -- App Server Secrets
    forex_api_key: dummy_val
    # -- Forex Api key for the fallback service
    # @section -- App Server Secrets
    forex_fallback_api_key: dummy_val
    # -- # Payment method auth key used for authorization
    # @section -- App Server Secrets
    pm_auth_key: dummy_val
    # -- API key hashing key.
    # @section -- App Server Secrets
    api_hash_key: 0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef
    # -- Encryption key used for encrypting data in user_authentication_methods table
    # @section -- App Server Secrets
    keymanager: 
      ca: "sample_ca"
      cert: "sample_cert"

  analytics:
    clickhouse:
      # -- Clickhouse database name
      # @section -- App Server Secrets
      database: default
      # -- Clickhouse host in http(s)://<URL>:<PORT> format
      # @section -- App Server Secrets
      host: http://clickhouse:8123
      # -- Clickhouse username
      # @section -- App Server Secrets
      username: default
      # -- Clickhouse password (optional)
      # @section -- App Server Secrets
      password: ''
    # -- The Analytics source/strategy to be used
    source: clickhouse
    sqlx:
      # -- Timeout for database connection in seconds
      connection_timeout: 10
      # -- Number of connections to keep open
      pool_size: 5
      # -- Add the queue strategy used by the database bb8 client
      queue_strategy: Fifo
    forex_enabled: false
  applepay_merchant_configs:
    # -- Apple pay gateway merchant endpoint
    applepay_endpoint: https://apple-pay-gateway.apple.com/paymentservices/registerMerchant
  cell_information:
    # -- Default CellID for Global Cell Information
    id: '12345'
  connector_onboarding:
    paypal:
      enabled: true
  connector_request_reference_id_config:
    # server.connector_request_reference_id_config.merchant_ids_send_payment_id_as_connector_request_id -- List of merchant ids for which the payment id should be sent as connector request id
    merchant_ids_send_payment_id_as_connector_request_id: "['merchant_id_1','merchant_id_2']"
  cors:
    # -- List of methods that are allowed
    allowed_methods: GET,POST,PUT,DELETE
    # -- Maximum time (in seconds) for which this CORS request may be cached.
    max_age: 30
    # -- If true, allows any origin to make requests
    wildcard_origin: true
  email:
    # -- The currently active email client
    active_email_client: SMTP
    # -- Number of days the api calls ( with jwt token ) can be made without verifying the email
    allowed_unverified_days: 1
    # -- AWS region used by AWS SES
    # @section -- App Server Secrets
    aws_region: us-east-1
    aws_ses:
      # -- The amazon resource name ( arn ) of the role which has permission to send emails
      # @section -- App Server Secrets
      email_role_arn: arn:aws:iam::123456789012:role/SendEmailRole
      # -- An identifier for the assumed role session, used to uniquely identify a session.
      # @section -- App Server Secrets
      sts_role_session_name: SendEmailRole
    # -- Recipient email for prod intent email
    # @section -- App Server Secrets
    prod_intent_recipient_email: business@example.com
    # -- Recipient email for recon request email
    # @section -- App Server Secrets
    recon_recipient_email: recon@example.com
    # -- Sender email
    # @section -- App Server Secrets
    sender_email: example@example.com
    smtp:
      # -- connection type to be used for the smtp server
      connection: plaintext
      # -- Host of the smtp server
      # @section -- App Server Secrets
      host: mailhog
      # -- Username for the smtp server
      username: ''
      # -- Password for the smtp server
      # @section -- App Server Secrets
      password: ''
      # -- Port of the smtp server
      port: '1025'
      # -- timeout for the smtp server connection
      timeout: 10
  encryption_management:
    # -- Encryption manager client to be used
    encryption_manager: no_encryption
  events:
    # -- The event sink to push events supports kafka or logs (stdout)
    source: kafka
    kafka:
      # -- Kafka topic to be used for incoming api events
      api_logs_topic: hyperswitch-api-log-events
      # -- Kafka topic to be used for PaymentAttempt events
      attempt_analytics_topic: hyperswitch-payment-attempt-events
      # -- Kafka topic to be used for Payment Audit events
      audit_events_topic: hyperswitch-audit-events
      # -- Kafka topic to be used for Authentication events
      authentication_analytics_topic: hyperswitch-authentication-events
      brokers: "['kafka0:29092']"
      # -- Kafka topic to be used for connector api events
      connector_logs_topic: hyperswitch-outgoing-connector-events
      # -- Kafka topic to be used for Consolidated events
      consolidated_events_topic: hyperswitch-consolidated-events
      # -- Kafka topic to be used for Dispute events
      dispute_analytics_topic: hyperswitch-dispute-events
      # -- Kafka topic to be used for Fraud Check events
      fraud_check_analytics_topic: hyperswitch-fraud-check-events
      # -- Kafka topic to be used for PaymentIntent events
      intent_analytics_topic: hyperswitch-payment-intent-events
      # -- Kafka topic to be used for outgoing webhook events
      outgoing_webhook_logs_topic: hyperswitch-outgoing-webhook-events
      # -- Kafka topic to be used for Payouts and PayoutAttempt events
      payout_analytics_topic: hyperswitch-payout-events
      # -- Kafka topic to be used for Refund events
      refund_analytics_topic: hyperswitch-refund-events
  forex_api:
    # Expiration time for data in cache as well as redis in seconds
    data_expiration_delay_in_seconds: 21600
    # Redis remains write locked for 100 s once the acquire_redis_lock is called
    redis_lock_timeout_in_seconds: 100
    # Time to expire for forex data stored in Redis
    redis_ttl_in_seconds: 172800
  generic_link:
    payment_method_collect:
      ui_config:
        logo: https://app.hyperswitch.io/HyperswitchFavicon.png
        merchant_name: HyperSwitch
        theme: '#4285F4'
      enabled_payment_methods:
        card: credit,debit
        bank_transfer: ach,bacs,sepa
        wallet: paypal,pix,venmo
    payout_link:
      enabled_payment_methods:
        card: credit,debit
      ui_config:
        logo: https://app.hyperswitch.io/HyperswitchFavicon.png
        merchant_name: HyperSwitch
        theme: '#4285F4'
  grpc_client:
    dynamic_routing_client:
      # -- Client Host
      host: localhost
      # -- Client Port
      port: 7000
      # -- Client Service Name
      service: "dynamo"
  theme:
    storage:
      # -- Theme storage backend to be used
      file_storage_backend: "aws_s3"
      aws_s3:
        # -- AWS region where the S3 bucket for theme storage is located
        region: "bucket_region"
        # -- AWS S3 bucket name for theme storage
        bucket_name: "bucket"
    email_config:
      # -- Name of the entity to be showed in emails
      entity_name: "HyperSwitch"
      # -- Logo URL of the entity to be used in emails
      entity_logo: "https://example.com/logo.png"
      # -- Foreground color of email text
      foreground_color: "#000000"
      # -- Primary color of email body
      primary_color: "#006DF9"
      # -- Background color of email body
      background_color: "#FFFFFF"
  connectors:
    # -- Unified Authentication Service Configuration
    unified_authentication_service:
      # -- base url to call unified authentication service  
      base_url: "http://localhost:8080"    

  lock_settings:
    # -- Delay between retries in milliseconds
    delay_between_retries_in_milliseconds: 500
    # -- Seconds before the redis lock expires
    redis_lock_expiry_seconds: 180
  # Locker settings contain details for accessing a card locker, a
  # PCI Compliant storage entity which stores payment method information
  # like card details
  locker:
    # -- Locker host
    host: http://hyperswitch-vault
    # -- Rust Locker host
    host_rs: null
    # -- Boolean to enable or disable saving cards in locker
    locker_enabled: true
    # -- Key_id to sign basilisk hs locker
    locker_signing_key_id: '1'
    # -- Emulate a locker locally using Postgres
    mock_locker: false
    # -- Time to live for storage entries in locker
    ttl_for_storage_in_secs: 220752000
  log:
    console:
      enabled: true
      # -- Log level for console logs, ERROR, WARN, INFO, DEBUG
      level: DEBUG
      log_format: json
    file:
      enabled: false
      level: DEBUG
      log_format: json
    # Telemetry configuration for metrics and traces
    telemetry:
      # -- Interval for collecting the metrics in background thread
      bg_metrics_collection_interval_in_secs: 15
      # -- boolean [true or false], whether to ignore errors during traces or metrics pipeline setup
      ignore_errors: false
      # -- boolean [true or false], whether metrics are enabled
      metrics_enabled: false
      # -- URL for external OpenTelemetry Collector endpoint to send metrics and traces to.
      # The OpenTelemetry Collector must have a gRPC OTLP receiver listening at this endpoint.
      # The value of `external_otel_collector_endpoint` will be considered even if the `opentelemetry-collector` subchart is enabled.
      external_otel_collector_endpoint: ""
      # -- timeout (in milliseconds) for sending metrics and traces
      otel_exporter_otlp_timeout: 5000
      route_to_trace: "['*/confirm']"
      sampling_rate: 0.1
      # -- boolean [true or false], whether traces are enabled
      traces_enabled: false
      # -- Set this to true for AWS X-ray compatible traces
      use_xray_generator: false
  # Main SQL data store credentials
  master_database:
    # -- Timeout for database connection in seconds
    connection_timeout: 10
    # -- Number of connections to keep open
    pool_size: '20'
    # -- Add the queue strategy used by the database bb8 client
    queue_strategy: Fifo
  multitenancy:
    enabled: false
    global_tenant:
      clickhouse_database: default
      redis_key_prefix: ""
      schema: public
      tenant_id : "global"
    tenants:
      public:
        base_url : "http://localhost:8080"
        schema: public
        accounts_schema: "public"
        redis_key_prefix: ""
        clickhouse_database: "default"
        user:
          control_center_url :  "http://localhost:9000"
  opensearch:
    auth:
      auth: basic
      username: admin
      password: admin
      region: eu-central-1
    host: https://localhost:9200
    enabled: false
    indexes:
      disputes: hyperswitch-dispute-events
      payment_attempts: hyperswitch-payment-attempt-events
      payment_intents: hyperswitch-payment-intent-events
      refunds: hyperswitch-refund-events
      sessionizer_disputes: sessionizer-dispute-events
      sessionizer_payment_attempts: sessionizer-payment-attempt-events
      sessionizer_payment_intents: sessionizer-payment-intent-events
      sessionizer_refunds: sessionizer-refund-events
  payment_method_auth:
    # -- Redis expiry time in milliseconds
    redis_expiry: 900
  paze_decrypt_keys:
    # -- Base 64 Encoded Private Key File cakey.pem generated for Paze -> Command to create private key: openssl req -newkey rsa:2048 -x509 -keyout cakey.pem -out cacert.pem -days 365
    # @section -- App Server Secrets
    paze_private_key: PAZE_PRIVATE_KEY
    # -- PEM Passphrase used for generating Private Key File cakey.pem
    # @section -- App Server Secrets
    paze_private_key_passphrase: PAZE_PRIVATE_KEY_PASSPHRASE
  google_pay_decrypt_keys:
    google_pay_root_signing_keys: GOOGLE_PAY_ROOT_SIGNING_KEYS
  proxy:
    # -- A comma-separated list of domains or IP addresses that should not use the proxy. Whitespace between entries would be ignored.
    bypass_proxy_hosts: "localhost, cluster.local"
    enabled: false
    # -- Outgoing proxy http URL to proxy the HTTP traffic
    http_url: http://proxy_http_url
    # -- Outgoing proxy https URL to proxy the HTTPS traffic
    https_url: https://proxy_https_url
  # Redis credentials
  redis:
    # -- Whether or not the client should automatically pipeline commands across tasks when possible.
    auto_pipeline: true
    # -- boolean
    cluster_enabled: false
    # -- List of redis cluster urls
    cluster_urls: "['redis.cluster.uri-1:8080', 'redis.cluster.uri-2:4115']"
    # -- An optional timeout to apply to all commands. In seconds
    default_command_timeout: 30
    # -- Default TTL for hashes entries, in seconds
    default_hash_ttl: 900
    # -- Default TTL for entries, in seconds
    default_ttl: 300
    # -- Whether or not to disable the automatic backpressure features when pipelining is enabled.
    disable_auto_backpressure: false
    host: 127.0.0.1
    # -- The maximum number of frames that will be fed to a socket before flushing.
    max_feed_count: 200
    # -- The maximum number of in-flight commands (per connection) before backpressure will be applied.
    max_in_flight_commands: 5000
    # -- Number of connections to keep open
    pool_size: 5
    port: 6379
    # -- Delay between reconnection attempts, in milliseconds
    reconnect_delay: 5
    # -- Maximum number of reconnection attempts to make before failing. Set to 0 to retry forever.
    reconnect_max_attempts: 5
    # -- Default number of entries to read from stream if not provided in stream read options
    stream_read_count: 1
    # -- An optional timeout for Unresponsive commands in seconds. This should be less than default_command_timeout.
    unresponsive_timeout: 10
    # -- RESP protocol for fred crate (set this to true if using RESPv2 or redis version < 6)
    use_legacy_version: false
  # Replica SQL data store credentials
  replica_database:
    # -- Timeout for database connection in seconds
    connection_timeout: 10
    # -- Number of connections to keep open
    pool_size: '20'
    # -- Add the queue strategy used by the database bb8 client
    queue_strategy: Fifo
  report_download_config:
    # -- Config to download dispute report
    dispute_function: report_download_config_dispute_function
    # -- Config to download payment report
    payment_function: report_download_config_payment_function
    # -- Config to download refund report
    refund_function: report_download_config_refund_function
    # -- Region of the bucket
    region: report_download_config_region
    # -- Config to authentication function
    authentication_function: report_download_config_authentication_function
  # -- Processor URLs will be decided based on this config, Eg: sandbox or production
  run_env: sandbox
  secrets_management:
    # -- Secrets manager client to be used
    secrets_manager: no_encryption
    hc_vault:
      url: http://vault:8200
      token: vault_token
  # Server configuration
  server:
    host: 0.0.0.0
    port: 8080
    # -- HTTP Request body limit. Defaults to 32kB
    request_body_limit: 32768
    # -- This is the grace time (in seconds) given to the actix-server to stop the execution
    # -- For more details: https://actix.rs/docs/server/#graceful-shutdown
    shutdown_timeout: 30
    workers: 8
  user:
    base_url: http://localhost:9000
    force_two_factor_auth: false
    password_validity_in_days: '90'
    totp_issuer_name: Hyperswitch Sandbox
    two_factor_auth_expiry_in_secs: '300'
    force_cookies: false
  user_auth_methods:
    encryption_key: "A8EF32E029BC3342E54BF2E172A4D7AA43E8EF9D2C3A624A9F04E2EF79DC698F"
# @ignored
consumer:
  # -- Number of replicas to be used for the application
  replicas: 1
  # -- Wait time allowed for the deployment before the deployment is marked as failed
  progressDeadlineSeconds: 600
  # -- The strategy that can be used to replace the old pods by new ones
  # @ignored
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  # Specify affinity for nodes to which the pods should start on
  # @ignored
  affinity: {}
  # -- The time kubernetes will wait after sending the termination signal to the pods
  # @ignored
  terminationGracePeriodSeconds: 30
  # -- Annotations that are to be added to the pods (extends global configuration)
  # @ignored
  podAnnotations:
    traffic_sidecar_istio_io_excludeOutboundIPRanges: 10.23.6.12/32
  # -- Annotations that are to be added the the deployments (extends global configuration)
  # @ignored
  annotations:
    deployment.kubernetes.io/revision: "1"
  # -- Labels to be added to the deployment's (match labels) and their pods (extends global configuration)
  # @ignored
  labels:
    app: hyperswitch-consumer
  # -- service account annotations to be used
  # @ignored
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn:
  # -- Environmant variables that are to be used by the hyperswitch application service this will extend the existing global configuration
  env:
    binary: consumer
# @ignored
producer:
  # -- Number of replicas to be used for the application
  replicas: 1
  # -- Wait time allowed for the deployment before the deployment is marked as failed
  progressDeadlineSeconds: 600
  # -- The strategy that can be used to replace the old pods by new ones
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  # -- Specify affinity for nodes to which the pods should start on
  # @ignored
  affinity: {}
  # -- The time kubernetes will wait after sending the termination signal to the pods
  terminationGracePeriodSeconds: 30
  # -- Annotations that are to be added to the pods (extends global configuration)
  podAnnotations:
    traffic_sidecar_istio_io_excludeOutboundIPRanges: 10.23.6.12/32
  # -- Annotations that are to be added the the deployments (extends global configuration)
  annotations:
    deployment.kubernetes.io/revision: "1"
  # -- Labels to be added to the deployment's (match labels) and their pods (extends global configuration)
  labels:
    app: hyperswitch-producer
  # -- service account annotations to be used
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn:
  # -- Environmant variables that are to be used by the hyperswitch application service this will extend the existing global configuration
  env:
    binary: producer

controlCenter:
  # -- Number of replicas to be used for the application
  replicas: 1
  # -- Wait time allowed for the deployment before the deployment is marked as failed
  # @ignored
  progressDeadlineSeconds: 600
  # -- The strategy that can be used to replace the old pods by new ones
  # @ignored
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  # -- Specify affinity for nodes to which the pods should start on
  # @ignored
  affinity: {}
  # -- The time kubernetes will wait after sending the termination signal to the pods
  # @ignored
  terminationGracePeriodSeconds: 30
  # -- Annotations that are to be added to the pods (extends global configuration)
  # @ignored
  podAnnotations:
    traffic_sidecar_istio_io_excludeOutboundIPRanges: 10.23.6.12/32
  # -- Annotations that are to be added the the deployments (extends global configuration)
  # @ignored
  annotations:
    deployment.kubernetes.io/revision: "1"
  # -- Labels to be added to the deployment's (match labels) and their pods (extends global configuration)
  # @ignored
  labels:
    app: hyperswitch-control-center
  # -- service account annotations to be used
  # @ignored
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn:
  env:
    # -- 
    binary: dashboard
    # -- Enables user sign-in and sign-up using magic links instead of passwords. When enabled, users can request a magic link via email that logs them into their account or creates a new account if they are signing up.
    # @section -- Control Center configs
    default__features__email: "true"
    # -- Enables customization of branding elements like logos, colors.
    # @section -- Control Center configs
    default__features__branding: "false"
    # -- Enables the ability to apply surcharges to payments. When enabled, you can create advanced rules based on payment parameters like amount, currency, and payment method to enforce surcharges as needed.
    # @section -- Control Center configs
    default__features__surcharge: "true"
    # -- Enables the simplified onboarding flow for new users, where they connect to processors, configure payment routing and test a payment, all in one flow.
    # @section -- Control Center configs
    default__features__quick_start: "true"
    # -- Enables access to reconciliation capabilities in the Hyperswitch dashboard. When turned on, this unlocks the Reconciliation module that allows users to match payment transactions with bank/ledger entries for accounting purposes.
    # @section -- Control Center configs
    default__features__recon: "true"
    # -- Enables the payout functionality in the dashboard. When enabled, this allows users to configure payout profiles, manage recipient details, schedule disbursements, and process payout batches to pay out funds to third parties.
    # @section -- Control Center configs
    default__features__payout: "true"
    # -- Enables the Fraud and Risk Management (FRM) module within the dashboard. When enabled, this unlocks integrations with FRM players like Riskified and Signified. https://docs.hyperswitch.io/explore-hyperswitch/payment-flows-and-management/fraud-and-risk-management
    # @section -- Control Center configs 
    default__features__frm: "true"
    # -- Controls the collection and transmission of anonymous usage data to Mixpanel for analytics. When enabled, the dashboard will automatically send information about user actions and events to Mixpanel without collecting any personally identifiable information via REST API.
    # @section -- Control Center configs
    default__features__mixpanel: "true"
    # -- Enables the ability to load simulated sample data into the dashboard for preview purposes. When enabled, dummy transactions, analytics, and reporting data can be generated.
    # @section -- Control Center configs
    default__features__sample_data: "true"
    # -- Enables the live mode - that the user is accessing. When enabled, it will show a visual indicator within the dashboard signaling whether the user is currently in a test environment or live production environment. In Live mode, current users are not allowed to sign up. Users must be created manually.
    # @section -- Control Center configs
    default__features__is_live_mode: "false"
    # -- Enables the ability for users to provide direct product feedback from within the dashboard. When enabled, a feedback modal will be available in the UI that allows users to rate features, report bugs, and suggest improvements. Disabling this flag will remove the feedback modal and prevent collection of any user data.
    # @section -- Control Center configs
    default__features__feedback: "false"
    # -- Enables the ability to generate detailed reports on payments, refunds, and disputes. When enabled, this allows users to pull reports covering the previous 6 months of transaction data. The reports can provide insights into trends, identify issues, and inform business decisions.
    # @section -- Control Center configs
    default__features__generate_report: "true"
    # -- Enables the ability to load simulated sample data into the dashboard for preview purposes.
    default__features__system_metrics: "false"
    # -- Enables users to toggle between test and live modes when signing in. When enabled, users will see an option during sign-in to actively switch between test and live environments.
    # @section -- Control Center configs
    default__features__test_live_toggle: "false"
    # -- Allows enabling sandbox/test payment processors for testing purposes. When enabled, developers and testers can add test payment processors like Stripe Test or PayPal Test to trial payment flows without touching live transactions or making processor API calls.
    # @section -- Control Center configs
    default__features__test_processors: "true"
    # -- Grants access to the user journey module within the analytics section of the dashboard. This feature provides comprehensive graphical representations of payment analytics, facilitating a deeper understanding of user behavior and usage patterns.
    # @section -- Control Center configs
    default__features__user_journey_analytics: "false"
    # -- Enables totp will mandate 2fa for all users
    # @section -- Control Center configs
    default__features__totp: "false"
    default__features__authentication_analytics: "false"
    default__features__compliance_certificate: "true"
    default__features__configure_pmts: "true"
    default__features__custom_webhook_headers: "false"
    default__features__dev_alt_payment_methods: false
    default__features__dev_click_to_pay: "true"
    default__features__dev_debit_routing: false
    default__features__dev_hypersense_v2_product: false
    default__features__dev_intelligent_routing_v2: false
    default__features__dev_modularity_v2: false
    default__features__dev_recon_v2_product: false
    default__features__dev_recovery_v2_product: false
    default__features__dev_vault_v2_product: false
    default__features__dev_webhooks: false
    default__features__dispute_analytics: "false"
    default__features__dispute_evidence_upload: "false"
    default__features__down_time: false
    default__features__force_cookies: false
    default__features__global_search: "true"
    default__features__global_search_filters: false
    default__features__granularity: false
    default__features__live_users_counter: "false"
    default__features__maintainence_alert: ""
    default__features__new_analytics: "true"
    default__features__new_analytics_filters: "true"
    default__features__new_analytics_refunds: "true"
    default__features__new_analytics_smart_retries: "true"
    default__features__performance_monitor: "true"
    default__features__pm_authentication_processor: "true"
    default__features__recon_v2: false
    default__features__tax_processors: "true"
    default__features__threeds_authenticator: "true"
    default__features__transaction_view: true
    default__features__tenant_user: "true"
    default__merchant_config__new_analytics__merchant_ids: []
    default__merchant_config__new_analytics__org_ids: []
    default__merchant_config__new_analytics__profile_ids: []
    # -- PCI DSS certificate url
    # @section -- Control Center configs
    default__endpoints__dss_certificate_url: "https://app.hyperswitch.io/certificates/PCI_DSS_v4-0_AOC_Juspay_2024.pdf"
    # -- Endpoints favicon url
    # @section -- Control Center configs
    default__endpoints__favicon_url: ""
    # -- Hyperswitch terms and conditions url
    # @section -- Control Center configs
    default__endpoints__agreement_url: "https://app.hyperswitch.io/agreement/tc-hyperswitch-aug-23.pdf"
    # -- Agreement version
    # @section -- Control Center configs
    default__endpoints__agreement_version: "1.0.0"
    default__endpoints__hypersense_url: ""
    # -- Mixpanel token
    # @section -- Control Center configs
    default__endpoints__mixpanel_token: "dd4da7f62941557e716fbc0a19f9cc7e"
    # -- Endpoints logo url
    default__endpoints__logo_url: ""
    default__endpoints__recon_iframe_url: ""
    # -- Primary color for the theme
    # @section -- Control Center configs
    default__theme__primary_color: "#006DF9"
    # -- Primary hover color for the theme
    # @section -- Control Center configs
    default__theme__primary_hover_color: "#005ED6"
    # -- Secondary color for the theme
    # @section -- Control Center configs
    default__theme__sidebar_color: "#242F48"
    default__theme__sidebar_border_color: "#ECEFF3"
    default__theme__sidebar_primary: "#FCFCFD"
    default__theme__sidebar_primary_text_color: "#1C6DEA"
    default__theme__sidebar_secondary: "#FFFFFF"
    default__theme__sidebar_secondary_text_color: "#525866"
    host: hyperswitch-control-center
    # -- Mix panel token
    # @section -- Control Center configs
    mixpanelToken: "dd4da7f62941557e716fbc0a19f9cc7e"

# https://artifacthub.io/packages/helm/bitnami/redis
redis:
  # -- - enable Bitnami redis sub-chart helm installation
  # @section -- Dependencies configuration
  enabled: true
  image:
    tag: 7.2.3-debian-11-r2
  master:
    # -- Number of replicas to be used for master
    # @section -- Dependencies configuration
    count: 1
  replica:
    # -- Number of replicas to be used for replica
    # @section -- Dependencies configuration
    replicaCount: 0
  auth:
    # -- enable or disable redis auth
    # @section -- Dependencies configuration
    enabled: false
    # -- enable or disable sentinel
    # @section -- Dependencies configuration
    sentinel: false

externalRedis:
  # -- Link this service to an external Redis server
  # @section -- Dependencies configuration
  enabled: false
  # -- External redis host
  # @section -- Dependencies configuration
  host: redis-ext-master
  auth:
    # -- auth enabled or disabled
    # @section -- Dependencies configuration
    enabled: true
    # -- redis username
    # @section -- Dependencies configuration
    username: ""
    # -- redis password
    # @section -- Dependencies configuration
    password: ""

redisMiscConfig:
  checkRedisIsUp:
    initContainer:
      enable: true
      image: docker.io/bitnami/redis:7.2.3-debian-11-r2
      maxAttempt: 60

# https://artifacthub.io/packages/helm/bitnami/postgresql
postgresql:
  # -- enable Bitnami postgresql sub-chart helm installation
  # @section -- Dependencies configuration
  enabled: true
  image:
    tag: 16.1.0-debian-11-r18
  global:
    postgresql:
      auth:
        # -- Postgresql username
        # @section -- Dependencies configuration
        username: "hyperswitch"
        # -- Postgresql password
        # @section -- Dependencies configuration
        password: "ZGJwYXNzd29yZDEx"
        # -- Postgresql database
        # @section -- Dependencies configuration
        database: "hyperswitch"
  # -- Postgresql architecture: replication or standalone
  # @section -- Dependencies configuration
  architecture: replication
  replication:
    # -- synchronous_commit parameter
    # @section -- Dependencies configuration
    synchronousCommit: "off"
    # -- Number of synchronous replicas
    # @section -- Dependencies configuration
    numSynchronousReplicas: 1
  primary:
    # -- postgres primary name
    # @section -- Dependencies configuration
    name: ""
    resources:
      requests:
        # -- CPU resource requests
        # @section -- Dependencies configuration
        cpu: 150m
  readReplicas:
    # -- Number of read replicas
    # @section -- Dependencies configuration
    replicaCount: 0
    resources:
      requests:
        # -- CPU resource requests
        # @section -- Dependencies configuration
        cpu: 100m

externalPostgresql:
  # -- Link this service to an external Postgres server
  # @section -- Dependencies configuration
  enabled: false
  primary:
    # -- External postgres host
    # @section -- Dependencies configuration
    host: "postgresql-ext"
    auth:
      # -- master DB username
      # @section -- Dependencies configuration
      username: "hyperswitch"
      # -- master DB password
      # @section -- Dependencies configuration
      password: "hyperswitch"
      # -- master DB plainpassword
      # @section -- Dependencies configuration
      plainpassword: 
      # -- master DB name
      # @section -- Dependencies configuration
      database: "hyperswitch"
  readOnly:
    # -- External postgres read only host enabled or disabled
    # @section -- Dependencies configuration
    enabled: false
    # -- External postgres read only host
    # @section -- Dependencies configuration
    host: "postgres-service"
    auth:
      # -- replica DB username
      # @section -- Dependencies configuration
      username: "hyperswitch"
      # -- replica DB password
      # @section -- Dependencies configuration
      password: "hyperswitch"
      # -- replica DB plainpassword
      # @section -- Dependencies configuration
      plainpassword: 
      # -- replica DB name
      # @section -- Dependencies configuration
      database: "hyperswitch"

initDB:
  enable: true
  checkPGisUp:
    image: docker.io/bitnami/postgresql:16.1.0-debian-11-r18
    maxAttempt: 60
  refs: tags # tags or heads
  migration:
    image: christophwurst/diesel-cli:latest

loadBalancer:
  targetSecurityGroup: "loadBalancer-sg"

autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80

hyperswitch-card-vault:
  enabled: true
  initDB:
    checkPGisUp:
      image: docker.io/bitnami/postgresql:16.1.0-debian-11-r18

# https://artifacthub.io/packages/helm/bitnami/kafka
kafka:
  # -- Enable Bitnami Kafka sub-chart helm installation
  # @section -- Dependencies configuration
  enabled: true
  # -- Name of the Kafka sub-chart
  # @section -- Dependencies configuration
  fullnameOverride: "kafka0"

  controller:
    # -- Number of replicas to be used for controller
    # @section -- Dependencies configuration
    replicaCount: 1
    resourcesPreset: "none"
  broker:
    # -- Number of replicas to be used for broker
    # @section -- Dependencies configuration
    replicaCount: 1
    resourcesPreset: "none"
  # broker:
  # replicaCount: 1
  zookeeper:
    # -- Number of replicas to be used for zookeeper
    # @section -- Dependencies configuration
    replicaCount: 1
  service:
    ports:
      # -- Client port for Kafka
      # @section -- Dependencies configuration
      client: 29092
  listeners:
    client:
      # -- Listener client protocol
      # @section -- Dependencies configuration
      protocol: "PLAINTEXT"
    interbroker:
      # -- Listener interbroker protocol
      # @section -- Dependencies configuration
      protocol: "PLAINTEXT"
    external:
      # -- Listener external protocol
      # @section -- Dependencies configuration
      protocol: "PLAINTEXT"
    controller:
      # -- Listener controller protocol
      # @section -- Dependencies configuration
      protocol: "PLAINTEXT"
  provisioning:
    # -- kafka provisioning replicationFactor
    # @section -- Dependencies configuration
    replicationFactor: 1
  # -- (tpl/string) -- Kafka extraConfig
  # @notationType -- tpl
  # @section -- Dependencies configuration
  extraConfig: |
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1

initCH:
  checkCHisUp:
    image: "docker.io/bitnami/clickhouse:24.3"
    maxAttempt: 30
# https://github.com/bitnami/charts/blob/main/bitnami/clickhouse/values.yaml 
clickhouse:
  host: "clickhouse"
  # -- Enable Bitnami Clickhouse sub-chart helm installation
  # @section -- Dependencies configuration
  enabled: true
  resourcesPreset: "none"
  # -- Name of the Clickhouse sub-chart
  # @section -- Dependencies configuration
  fullnameOverride: "clickhouse"
  auth:
    # -- Clickhouse username
    # @section -- Dependencies configuration
    username: "default"
    # -- Clickhouse password
    # @section -- Dependencies configuration
    password: ""
  image:
    tag: 24.3
  config:
    # -- Clickhouse timezone
    # @section -- Dependencies configuration
    TZ: Asia/Kolkata
  # -- Clickhouse shard count
  # @section -- Dependencies configuration
  shards: 1
  # -- Clickhouse replica count
  # @section -- Dependencies configuration
  replicaCount: 1
  zookeeper:
    # -- Zookerper replica count
    # @section -- Dependencies configuration
    replicaCount: 1
  # -- Clickhouse log level
  # @section -- Dependencies configuration
  logLevel: "error"
  # @ignored
  initContainers:
  # @ignored
  extraVolumeMounts:
    - name: initdb-scripts
      mountPath: /docker-entrypoint-initdb.d
  # @ignored
  extraVolumes:
    - name: initdb-scripts
      emptyDir: {}

# https://artifacthub.io/packages/helm/codecentric/mailhog
mailhog:
  # -- Enable Bitnami Mailhog sub-chart helm installation for email testing
  # @section -- Dependencies configuration
  enabled: true
  # -- Name of the Mailhog sub-chart
  # @section -- Dependencies configuration
  fullnameOverride: "mailhog"

loki: 
  host: "loki"
  port: 3100

# https://github.com/grafana/helm-charts/tree/main/charts/loki-stack
loki-stack:
  loki:
    # -- Enable Bitnami Loki sub-chart helm installation
    # @section -- Dependencies configuration
    enabled: true
    isDefault: false
    # -- Name of the Loki sub-chart
    # @section -- Dependencies configuration
    fullnameOverride: "loki"
  promtail:
    # -- Enable Bitnami Promtail sub-chart helm installation
    # @section -- Dependencies configuration
    enabled: true
    # @ignored
    config:
      clients:
        - url: http://loki:3100/loki/api/v1/push
      snippets:
        extraRelabelConfigs:
          - action: "keep"
            regex: "hyperswitch-.*"
            source_labels: ["__meta_kubernetes_pod_label_app"]
  grafana:
    # -- Enable Bitnami Grafana sub-chart helm installation
    # @section -- Dependencies configuration
    enabled: true
    # -- Name of the Grafana sub-chart
    # @section -- Dependencies configuration
    adminPassword: "admin"
    image: 
      # -- Grafana image tag
      # @section -- Dependencies configuration
      tag: 10.0.1
    plugins:
    - volkovlabs-variable-panel
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
          - name: dp1
            orgId: 1
            folder: ''
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/dp1
          - name: dp2
            orgId: 1
            folder: ''
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/dp2
    dashboardsConfigMaps:
      dp1: "grafana-dashboard-payments"
      dp2: "grafana-dashboard-pod-usage"
    extraVolumes:
      - name: dashboards
        emptyDir: {}
    extraVolumeMounts:
      - name: dashboards
        mountPath: /var/lib/grafana/dashboards
  prometheus:
    enabled: false 
    prometheus-pushgateway:
      enabled: false
      tolerations: []

# https://artifacthub.io/packages/helm/vector/vector
vector:
  # -- Enable Bitnami Vector sub-chart helm installation
  # @section -- Dependencies configuration
  enabled: true
  env: 
    # -- Vector environment variables
    # @section -- Dependencies configuration
    - name: KAFKA_HOST
      value: "kafka0:29092"
  # @ignored
  customConfig:
  
    acknowledgements:
      enabled: true
    # enrichment_tables:
    #   sdk_map:
    #     type: file
    #     file:
    #       path: /etc/vector/config/sdk_map.csv
    #       encoding:
    #         type: csv
    #     schema:
    #       publishable_key: string
    #       merchant_id: string


    api:
      enabled: true
      address: 0.0.0.0:8686

    sources:
      kafka_tx_events:
        type: kafka
        bootstrap_servers: kafka0:29092
        group_id: sessionizer
        topics:
          - hyperswitch-payment-attempt-events
          - hyperswitch-payment-intent-events
          - hyperswitch-refund-events
          - hyperswitch-dispute-events
        decoding:
          codec: json

      sessionized_kafka_tx_events:
        type: kafka
        bootstrap_servers: kafka0:29092
        group_id: sessionizer
        topics:
          - ^sessionizer
        decoding:
          codec: json

      app_logs:
        type: docker_logs
        include_labels:
          - "logs=promtail"

      vector_metrics:
        type: internal_metrics

      node_metrics:
        type: host_metrics

      sdk_source:
        type: http_server
        address: 0.0.0.0:3103
        encoding: json

    transforms:
      events_create_ts:
        inputs:
        - kafka_tx_events
        source: |-
          .timestamp = from_unix_timestamp(.created_at, unit: "seconds") ?? now()
          ."@timestamp" = from_unix_timestamp(.created_at, unit: "seconds") ?? now()
        type: remap

      plus_1_events:
        type: filter
        inputs:
          - events_create_ts
          - sessionized_events_create_ts
        condition: ".sign_flag == 1"

      hs_server_logs:
        type: filter
        inputs:
          - app_logs
        condition: '.labels."com.docker.compose.service" == "hyperswitch-server"'

      parsed_hs_server_logs:
        type: remap
        inputs:
          - app_logs
        source: |-
          .message = parse_json!(.message)

      sessionized_events_create_ts:
        type: remap
        inputs:
        - sessionized_kafka_tx_events
        source: |-
          .timestamp = from_unix_timestamp(.created_at, unit: "milliseconds") ?? now()
          ."@timestamp" = from_unix_timestamp(.created_at, unit: "milliseconds") ?? now()

      sdk_transformed:
        type: throttle
        inputs:
          - sdk_source
        key_field: "{{ .payment_id }}{{ .merchant_id }}"
        threshold: 1000
        window_secs: 60
      
      amend_sdk_logs:
        type: remap
        inputs:
          - sdk_transformed
        source: |
          .before_transform = now()

          merchant_id = .merchant_id
          # row = get_enrichment_table_record!("sdk_map", { "publishable_key" : merchant_id }, case_sensitive: true) 
          # .merchant_id = row.merchant_id

          .after_transform = now()

      

    sinks:
      opensearch_events_1:
        type: elasticsearch
        inputs:
          - plus_1_events
        endpoints:
          - "https://opensearch:9200"
        id_key: message_key
        api_version: v7
        tls:
          verify_certificate: false
          verify_hostname: false
        auth:
          strategy: basic
          user: admin
          password: 0penS3arc#
        encoding:
          except_fields:
            - message_key
            - offset
            - partition
            - topic
            - clickhouse_database
            - last_synced
            - sign_flag
        bulk:
          index: "vector-{{ .topic }}"

      opensearch_events_2:
        type: elasticsearch
        inputs:
          - plus_1_events
        endpoints:
          - "https://opensearch:9200"
        id_key: message_key
        api_version: v7
        tls:
          verify_certificate: false
          verify_hostname: false
        auth:
          strategy: basic
          user: admin
          password: 0penS3arc#
        encoding:
          except_fields:
            - message_key
            - offset
            - partition
            - topic
            - clickhouse_database
            - last_synced
            - sign_flag
        bulk:
          # Add a date suffixed index for better grouping
          index: "vector-{{ .topic }}-%Y-%m-%d"

      opensearch_events_3:
        type: elasticsearch
        inputs:
          - plus_1_events
        endpoints:
          - "https://opensearch:9200"
        id_key: message_key
        api_version: v7
        tls:
          verify_certificate: false
          verify_hostname: false
        auth:
          strategy: basic
          user: admin
          password: 0penS3arc#
        encoding:
          except_fields:
            - message_key
            - offset
            - partition
            - topic
            - clickhouse_database
            - last_synced
            - sign_flag
        bulk:
          index: "{{ .topic }}"

      opensearch_logs:
        type: elasticsearch
        inputs:
          - parsed_hs_server_logs
        endpoints:
          - "https://opensearch:9200"
        api_version: v7
        tls:
          verify_certificate: false
          verify_hostname: false
        auth:
          strategy: basic
          user: admin
          password: 0penS3arc#
        bulk:
          # Add a date suffixed index for better grouping
          # index: "vector-{{ .topic }}-%Y-%m-%d"
          index: "logs-{{ .container_name }}-%Y-%m-%d"

      log_events:
        type: loki
        inputs:
          - kafka_tx_events
          - sessionized_kafka_tx_events
        endpoint: http://loki:3100
        labels:
          source: vector
          topic: "{{ .topic }}"
          job: kafka
        encoding:
          codec: json

      log_app_loki:
        type: loki
        inputs:
          - parsed_hs_server_logs
        endpoint: http://loki:3100
        labels:
          source: vector
          job: app_logs
          container: "{{ .container_name }}"
          stream: "{{ .stream }}"
        encoding:
          codec: json

      metrics:
        type: prometheus_exporter
        inputs:
          - vector_metrics
          - node_metrics

      sdk_sink:
        type: kafka
        encoding:
          codec: json
          except_fields:
            - "path"
            - "source_type"
        inputs:
          - "amend_sdk_logs"
        bootstrap_servers: kafka0:29092
        topic: hyper-sdk-logs
        key_field: ".merchant_id"

prometheus:
  host: "prometheus-server"
  port: 80

opentelemetry-collector:
  enabled: true

  mode: "deployment"

  # Specify which namespace should be used to deploy the resources into
  namespaceOverride: ""

  presets:
    kubernetesAttributes:
      enabled: true
      extractAllPodLabels: true
      extractAllPodAnnotations: false

  alternateConfig:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317

    processors:
      batch: {}
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      # Adds resource attributes (added by k8sattributes processor) as metrics labels
      transform:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["source_namespace"], resource.attributes["k8s.namespace.name"])
              - set(attributes["source_pod"], resource.attributes["k8s.pod.name"])
              - set(attributes["source_app"], resource.attributes["app"])
              - set(attributes["source_version"], resource.attributes["version"])

    exporters:
      debug:
        verbosity: detailed
      prometheus:
        endpoint: ${env:MY_POD_IP}:9898

    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133

    service:
      telemetry:
        logs:
          level: DEBUG
          encoding: json
        metrics:
          level: detailed
          address: ${env:MY_POD_IP}:8888
      extensions:
        - health_check
      pipelines:
        metrics:
          receivers:
            - otlp
          processors:
            - memory_limiter
            - transform
            - batch
          exporters:
            - prometheus

  image:
    repository: docker.io/otel/opentelemetry-collector-contrib
    tag: 0.122.1

  nodeSelector: {}
  tolerations: []
  affinity: {}

  ports:
    otlp:
      enabled: true
      containerPort: 4317
      servicePort: 4317
      protocol: TCP
      appProtocol: grpc
    otel-metrics:
      enabled: false
      containerPort: 8888
      servicePort: 8888
      protocol: TCP
    hs-metrics:
      enabled: true
      containerPort: 9898
      servicePort: 9898
      protocol: TCP
    otlp-http:
      enabled: false
    jaeger-compact:
      enabled: false
    jaeger-thrift:
      enabled: false
    jaeger-grpc:
      enabled: false
    zipkin:
      enabled: false

  resources:
    # Due to the `k8sattributes` processor, the collector uses more than 2 GiB of RAM and 1000+m vCPU  at startup,
    # and later drops to ~300 MiB of RAM and ~200m vCPU.
    limits:
      cpu: 1500m
      memory: 4Gi
    requests:
      cpu: 250m
      memory: 512Mi

  replicaCount: 1

  serviceMonitor:
    enabled: false
    metricsEndpoints:
      - port: otel-metrics
        honorLabels: true
        interval: 30s
        path: /metrics
      - port: hs-metrics
        honorLabels: true
        interval: 15s
        path: /metrics
